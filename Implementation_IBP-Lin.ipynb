{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By unveiling the latent variables that can generate observed properties of objects is one of the most fundamental issues in unsupervised learning. However, one of the crucial problems of unsupervised learning algorithms is to detect the latent structure. In K-means problem for example, we need to determine the number of clusters. One classic way is by performing model selection, while the other way is to use a Bayesian nonparametric method. One important method of Bayesian nonparametric method is the Indian buffet process (IBP), which is a stochastic process that provides a probability distribution over equivalence classes of binary matrices of bounded rows and potentially infinite columns. \n",
    "\n",
    "In this report, we first implement the Indian buffet process by Gibbs sampling and Metropolis-Hasting algorithm in python. For improvement in efficiency, we perform matrix calculation optimization indicated from Griffiths&Ghahramani's complete paper[1] and utilize parallel programming, JIT and Cython to decrease the computation duration. Moreover, we use check the validity and effectiveness of our acceleration and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "def timer(f, *args, **kwargs):\n",
    "    start = time.clock()\n",
    "    ans = f(*args, **kwargs)\n",
    "    return ans, time.clock() - start\n",
    "def report(fs, *args, **kwargs):\n",
    "    ans, t = timer(fs[0], *args, **kwargs)\n",
    "    print('%s: %.1f' % (fs[0].__name__, 1.0))  \n",
    "    for f in fs[1:]:\n",
    "        ans_, t_ = timer(f, *args, **kwargs)\n",
    "        print('%s: %.1f' % (f.__name__, t/t_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: Indian Buffet Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian restaurants in London offer buffets with an apparently infinite number of dishes. Indian buffet process (IBP) is a distribution over infinite binary matrices, specifying how customers (objects) choose dishes (features).\n",
    "\n",
    "N customers enter a restaurant one after another. Each customer is exposed to a buffet consisting of infinitely many dishes arranged in a line. The first customer starts at the left of the buffet and takes a serving from each dish, stopping after certain number of dishes which follows a Poisson($\\alpha$) distribution. The ith customer moves along the buffet, sampling dishes based on their \"popularity\". The ith customer takes dish k with probability $\\frac{m_k}{i}$, where $m_k$ is the number of previous customers who have sampled that dish. Having reached the end of all previous sampled dishes, the ith customer then tries a Poisson($\\frac{\\alpha}{i}$) number of new dishes. In conclusion, except the first customer(object), all the following customers(objects)'s choice can be divided into two parts. The first part depends on all the previous information and can be treated as Bernoulli trials, while the second part goes beyond the number of dishes from before and the number of \"new dishes\" follows a Poisson distribution with a new rate of $\\frac{\\alpha}{i}$.\n",
    "\n",
    "We can indicate which customers chose which dishes using a binary matrix Z with N rows and infinitely many columns, where $z_{ik}$ = 1 if the ith customer sampled the kth dish. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"IBPfigure6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Feature binary matrix Z with entry either 0 or 1\n",
    "\n",
    "* Number of new features $K_{new}$ having a Poisson distribution\n",
    "\n",
    "* Parameter $\\alpha$: $K_{new}$'s distribution parameter\n",
    "\n",
    "* $\\sigma^2_X$: Covariance of Gaussian Distribution on x\n",
    "\n",
    "* $\\sigma^2_A$: Covariance of Gaussian Distribution prior on A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Data Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the example in the paper before optimization, we have followed the quotation below from the original paper to generate data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"As a first demonstration of the ability of this algorithm to recover the latent structure responsible\n",
    "for having generated observed data, we applied the Gibbs sampler for the infinite linear-Gaussian\n",
    "model to a simulated data set consisting of 100 6×6 images, each generated by randomly assigning\n",
    "a feature to each image to a class with probability 0.5, and taking a linear combination of the\n",
    "weights associated with features to which the images were assigned (a similar data set was used by\n",
    "Ghahramani, 1995).  The non-zero elements of A were all equal to 1.0, and σX was set to\n",
    "0.5, introducing a large amount of noise. The data were generated from a model with K+ = 4 \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The \"A\" is constructed based on the example in a more complete paper by the same authors we find called \"The Indian Buffet Process: An Introduction and Review\" (Griffiths&Ghahramani, 2011). We have used this as a supplement to the given paper for enhancing our understanding of IBP. We have also used a trick in calculating the inverse as described in the paper when we imlement IBP later in this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file scripts/data_initialization.py\n",
    "import numpy as np\n",
    "np.random.seed(124)\n",
    "N = 100 \n",
    "K_plus = 4 \n",
    "D = 36 \n",
    "sigmaX = 0.5\n",
    "sigmaA = 0.5\n",
    "# Simulated data\n",
    "A = np.array(( 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, \\\n",
    "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0,1, 1, 1,0, 0, 0,  1, 0, 1, 0, 0, 0, 1, 1, 1,    \\\n",
    "             1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0,0, 0, 0, 0, 0,0 ,0, 0, \\\n",
    "             0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,0, 0, 0, 0,1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)).reshape(4, D)\n",
    "\n",
    "Z_zero = np.zeros((N, K_plus))\n",
    "X = np.zeros((N, D))\n",
    "I = np.identity(D) * sigmaX\n",
    "\n",
    "for i in range(N):\n",
    "    Z_zero[i,:] = (np.random.uniform(0,1,K_plus) > .5).astype(int)\n",
    "    while (np.sum(Z_zero[i,:]) == 0):\n",
    "        Z_zero[i,:] = (np.random.uniform(0,1,K_plus) > .5).astype(int)\n",
    "    X[i,:] = np.random.normal(0,1, (1,D)).dot(I)+Z_zero[i,:].dot(A)\n",
    "\n",
    "np.save(\"data/X_initialized\", X)\n",
    "np.save(\"data/A_initialized\", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm for Metropolis Hastings\n",
    "#### Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infinite latent feature model (likelihood)\n",
    "In our finite model, the $D$-dimensional vector of properties of an object i, $x_i$ is generated from a Gaussian distribution with mean $z_iA$ and covariance matrix $\\Sigma X = \\sigma^2_X $ I, where $z_i$ is a $K$-dimensional binary vector, and A is a $K$ $\\times$ $D$ matrix of weights. In matrix notation, E[X] = ZA. If Z is a feature matrix, this is a form of binary factor analysis. The distribution of X given Z, A, and $\\sigma$ X is matrix Gaussian with mean ZA and covariance matrix $\\sigma^2_X$ I, where I is the identity matrix. The prior on A is also matrix Gaussian, with mean 0 and covariance matrix $\\sigma^2_X$ I. Integrating out A, we have:\n",
    "\n",
    "\\begin{multline}\n",
    "P(X|Z,\\sigma_X, \\sigma_A) = \\frac{1}{(2 \\pi)^{ND/2} (\\sigma_X)^{(N-K)D}(\\sigma_A)^{KD}(|Z^TZ+\\frac{\\sigma_X^2}{\\sigma_A^2}I|)^{D/2}}\\\\exp\\{-\\frac{1}{2\\sigma_X^2}tr(X^T(I-Z(Z^TZ+\\frac{\\sigma_X^2}{\\sigma_A^2}I)^{-1}Z^T)X)\\}\n",
    "\\end{multline}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file scripts/original_functions.py\n",
    "#prior of IBP\n",
    "import math\n",
    "def IBP_prior(alpha, N):\n",
    "    import numpy as np\n",
    "    res = np.zeros((N, 1000))\n",
    "\n",
    "    #First person\n",
    "    temp = np.random.poisson(alpha)\n",
    "    if temp > 0:\n",
    "        res[0,0:temp] = np.ones(temp)\n",
    "\n",
    "    #the rest with Bernoulli + Poisson\n",
    "    K_plus = temp\n",
    "    for i in range(1,N):\n",
    "        for j in range(K_plus):\n",
    "            p = np.sum(res[0:i,j])/(i+1)\n",
    "    #sample as Bernoulli with rate m_k/i\n",
    "            if np.random.uniform(0,1) < p:\n",
    "                res[i,j] = 1\n",
    "    #The \"untouched\" dishes are got from poisson distribution with rate alpha/i\n",
    "        temp = np.random.poisson(alpha/(i+1))\n",
    "    #None zero\n",
    "        if temp > 0:\n",
    "    #The \"new dishes\", silimar logic as the very first person\n",
    "            res[i, K_plus : K_plus + temp] = np.ones(temp)\n",
    "    #length of new person's first few \"bernoulli\" choice \n",
    "            K_plus = K_plus + temp\n",
    "    \n",
    "    res = res[:,0:K_plus]\n",
    "    return np.array((res, K_plus))\n",
    "\n",
    "# define a log likelihood function \n",
    "def log_p_origin(X, Z, sigmaX, sigmaA, K, D, N):\n",
    "    import numpy as np\n",
    "    return (-1)*np.log(2*np.pi)*N*D*.5 - np.log(sigmaX)*(N-K)*D - np.log(sigmaA)*K*D - .5*D*np.log(np.linalg.det(Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K))) -.5/(sigmaX**2)*np.trace( (X.T.dot( np.identity(N)-Z.dot(np.linalg.inv(Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K)).dot(Z.T)) )).dot(X) )\n",
    "\n",
    "\n",
    "# define a log likelihood function \n",
    "def log_p(X, Z, sigmaX, sigmaA, K, D, N):\n",
    "    import numpy as np\n",
    "    M = Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K)\n",
    "    return (-1)*np.log(2*np.pi)*N*D*.5 - np.log(sigmaX)*(N-K)*D - np.log(sigmaA)*K*D - .5*D*np.log(np.linalg.det(M)) -.5/(sigmaX**2)*np.trace( (X.T.dot( np.identity(N)-Z.dot(np.linalg.inv(M).dot(Z.T)) )).dot(X) )\n",
    "\n",
    "def calcInverse(Z,M,i,k):\n",
    "    import numpy as np\n",
    "    \"\"\"New inverse calculation as described in Griffiths and Ghahramani(2011)\"\"\"\n",
    "    M_i = M - M.dot(Z[i,:].T.dot(Z[i,:].dot(M)))/(Z[i,:].dot(M.dot(Z[i,:].T))-1)\n",
    "    M = M_i - M_i.dot(Z[i,:].T.dot(Z[i,:].dot(M_i)))/(Z[i,:].dot(M_i.dot(Z[i,:].T))+1)\n",
    "    Inv = M\n",
    "    return Inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gibbs Samplers and Metropolis Algorithm\n",
    "\n",
    "Full conditional posterior for Z is:\n",
    "$$P(z_{ik}|X,Z_{-(i,k),},\\sigma_X,\\sigma_A) \\propto  P(X|Z,\\sigma_X, \\sigma_A) P(z_{ik}=1|\\textbf{z}_{-i,k}) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full (posterior) conditional distribution is\n",
    "P(zik|X,Z−i,k,σX,σA) ∝ P(X|Z−i,k,σX,σA)P(zik|z−i,k) (6)\n",
    "When initializing the Gibbs sampler, set σA = 1,σX = 1,α ∼ Ga(1,1). Then the sampler does the following steps: (K in my code is denoted as K+, to differentiate it from the true value.)\n",
    "1. Generate P(zik|X,Z−i,k,σX,σA) using the full conditional distribution (a) Remove singular features (at most one object has it);\n",
    "decrease K+ by 1 for each feature removed (b) Determine each zik to be 0 or 1 by Metropolis\n",
    "(c) Add new features from Pois(α) i\n",
    "2. Sample σX∗ = σX + ε, where ε ∼ Unif(−0.05, 0.05), and accept σX∗ by Metropolis\n",
    "3. Sample σA∗ = σA + ε, where ε ∼ Unif(−0.05, 0.05), and accept σA∗ by Metropolis\n",
    "4. Generate α|Z ∼ Ga(1 + K+, 1 + 􏰀Ni=1 Hi), where K+ is the number of features with mk > 0\n",
    "The Metropolis part for σA is demonstrated as follows (similar case for σX): • Genenerate a candidate value σA∗ = σA + ε, with ε ∼ Unif(−0.05, 0.05) • Generate a random number r ∼ Unif(0, 1)\n",
    "• Accept σA∗ if r < min{1, P (σA∗ |Z, X, σX ) }, where σA is the current value P(σA|Z,X,σX)\n",
    "The candidate value σA∗ is always accepted when the likelihood ratio P (σA∗ |Z, X, σX ) is larger than 1, P(σA|Z,X,σX)\n",
    "i.e. P (σA∗ |Z, X, σX ) > P (σA|Z, X, σX ). Nevertheless, when the likelihood ratio is less than 1, there is still a non-zero probability to accept σA∗ , so the sampler can ”move forward”. Note that in my code, the log likelihoods are used in the following way:\n",
    "min{1, P(σA∗ |Z,X,σX)} = exp(min{0,log(P(σA∗ |Z,X,σX)) − log(P(σA|Z,X,σX))}) (7)\n",
    "Finally, the posterior expectation of A is:\n",
    "E(A|X,Z)=(ZZ+σA2I) ZX (8)\n",
    "This is denoted as Ainf, with size D × K+, and Ainf is the matrix of latent features (images) my code converges to. For the ith image, replace Z with only the ith row zi, and the resulting Ainf,i is the corresponding reversed image string (a linear combination of the K+ bases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scripts/gibbs_sampler.py\n"
     ]
    }
   ],
   "source": [
    "%%file scripts/gibbs_sampler.py\n",
    "import numpy as np\n",
    "import math\n",
    "def Update_alpha(N,Kplus):\n",
    "    Harmonic_N = 0.\n",
    "    for i in range(1, N+1):\n",
    "        Harmonic_N += 1.0/i\n",
    "    alpha = np.random.gamma(1+Kplus, 1/(1+Harmonic_N))\n",
    "    return alpha\n",
    "\n",
    "def Update_sigmaA(X, Z, sigmaX, sigmaA, Kplus, D, N,Log_L1):\n",
    "    temp_unif1 = np.random.uniform(0,1)/30\n",
    "    if np.random.uniform(0,1) < .5:\n",
    "        sigmaA_new = sigmaA - temp_unif1\n",
    "    else:\n",
    "        sigmaA_new = sigmaA + temp_unif1\n",
    "\n",
    "    Log_L_New = log_p(X, Z, sigmaX, sigmaA_new, Kplus, D, N)\n",
    "    sigmaX_a = np.exp(min(0,Log_L_New-Log_L1))\n",
    "    U = np.random.uniform(0,1)\n",
    "    if U < sigmaX_a:\n",
    "        sigmaA = sigmaA_new\n",
    "    return sigmaA\n",
    "\n",
    "def Update_sigmaX(X, Z, sigmaX, sigmaA, Kplus, D, N,Log_L1):\n",
    "    temp_unif = np.random.uniform(0,1)/30\n",
    "    if np.random.uniform(0,1) < .5:\n",
    "        sigmaX_new = sigmaX - temp_unif\n",
    "    else:\n",
    "        sigmaX_new = sigmaX + temp_unif\n",
    "    Log_L_New = log_p(X, Z, sigmaX_new, sigmaA, Kplus, D, N)\n",
    "    sigmaX_a = np.exp(min(0,Log_L_New-Log_L1))       \n",
    "    U = np.random.uniform(0,1)\n",
    "    if U < sigmaX_a:\n",
    "        sigmaX = sigmaX_new\n",
    "    return(sigmaX)\n",
    "\n",
    "#M-H algorithm for Kplus\n",
    "#Sample number of new features\n",
    "def Update_Kplus(X,Z,maxNew,sigmaX, sigmaA,alpha,N,D,Kplus,log_p):\n",
    "    prob = np.zeros(maxNew)\n",
    "    alphaN = alpha/N     \n",
    "    for kNew in range(maxNew):\n",
    "        Z_temp = Z\n",
    "        if kNew > 0:\n",
    "            addCols = np.zeros((N,kNew))\n",
    "            addCols[i,:] = 1\n",
    "            Z_temp = np.hstack((Z_temp, addCols))\n",
    "\n",
    "        pois = kNew*np.log(alphaN) - alphaN - np.log(math.factorial(kNew))\n",
    "        kk = Kplus+kNew\n",
    "        lik = log_p(X, Z_temp, sigmaX, sigmaA, kk, D, N)\n",
    "        prob[kNew] = pois + lik\n",
    "    prob = np.exp(prob - max(prob))\n",
    "    prob = prob/sum(prob)\n",
    "\n",
    "    U = np.random.uniform(0,1)\n",
    "    p = 0\n",
    "    kNew=0\n",
    "    for new in range(maxNew):\n",
    "        p = p + prob[new]\n",
    "        if U < p:\n",
    "            kNew = new\n",
    "            break\n",
    "    if kNew > 0:\n",
    "        addCols = np.zeros((N,kNew))\n",
    "        addCols[i,:] = 1\n",
    "        Z = np.hstack((Z, addCols))\n",
    "    Kplus = Kplus + kNew\n",
    "    return Kplus,Z\n",
    "\n",
    "def Update_Z(i,X,Kplus,Z,sigmaX,sigmaA,D,N,log_p):\n",
    "    for k in range(Kplus):\n",
    "        if k >= Kplus:\n",
    "            break     \n",
    "        if Z[i,k] > 0:\n",
    "            if (np.sum(Z[:,k])- 1) <= 0:\n",
    "                Z[:,k:(Kplus-1)] = Z[:,(k+1):Kplus]\n",
    "                Kplus = Kplus-1\n",
    "                Z = Z[:,0:Kplus]\n",
    "                continue\n",
    "\n",
    "        #M-H algorithm for Z\n",
    "        P = np.zeros(2)\n",
    "        #set Z[i,k] = 0 and calculate posterior probability\n",
    "        Z[i,k] = 0\n",
    "        P[0] = log_p(X, Z, sigmaX, sigmaA, Kplus, D, N) + np.log(N-np.sum(Z[:,k])) - np.log(N)\n",
    "        #set Z[i,k] = 1 and calculate posterior probability\n",
    "        Z[i,k] = 1\n",
    "        P[1] = log_p(X, Z,sigmaX, sigmaA, Kplus, D, N)  + np.log(np.sum(Z[:,k])- 1) - np.log(N)\n",
    "\n",
    "        P = np.exp(P - max(P))\n",
    "        U = np.random.uniform(0,1)\n",
    "        if U<(P[1]/(np.sum(P))):\n",
    "            Z[i,k] = 1\n",
    "        else:\n",
    "            Z[i,k] = 0   \n",
    "    return Z,Kplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scripts/original_sampler.py\n"
     ]
    }
   ],
   "source": [
    "%%file scripts/original_sampler.py\n",
    "import numpy as np\n",
    "from gibbs_sampler import Update_Z,Update_Kplus,Update_sigmaX,Update_sigmaA,Update_alpha\n",
    "from original_functions import log_p, IBP_prior, log_p_origin\n",
    "# Original sampler with either original likelihood or improved likelihood\n",
    "def sampler(X, niter, sigmaX, sigmaA,alpha, N, D, maxNew, log_p):\n",
    "\n",
    "#initialization\n",
    "    count=0\n",
    "    final_Z=np.zeros((niter,N,20))\n",
    "    final_K=np.zeros((niter,1))\n",
    "    final_sigma_X=np.zeros((niter,1))\n",
    "    final_sigma_A=np.zeros((niter,1))\n",
    "    final_alpha=np.zeros((niter,1))\n",
    "    Z, Kplus = IBP_prior(alpha, N)\n",
    "    \n",
    "#repeat \"niter\" number of times\n",
    "    for j in range(niter):\n",
    "        final_Z[count,:,0:Kplus] = Z\n",
    "        final_K[count] = Kplus\n",
    "        final_sigma_X[count] = sigmaX\n",
    "        final_sigma_A[count] = sigmaA\n",
    "        final_alpha[count] = alpha\n",
    "        count = count + 1\n",
    "\n",
    "        for i in range(N):\n",
    "            Z,Kplus = Update_Z(i,X,Kplus,Z,sigmaX,sigmaA,D,N,log_p)\n",
    "            Kplus,Z = Update_Kplus(X,Z,maxNew,sigmaX, sigmaA,alpha,N,D,Kplus,log_p)\n",
    "        Log_L1 = log_p(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "        sigmaX = Update_sigmaX(X, Z, sigmaX, sigmaA, Kplus, D, N,Log_L1)\n",
    "        sigmaA = Update_sigmaA(X, Z, sigmaX, sigmaA, Kplus, D, N,Log_L1)\n",
    "        alpha = Update_alpha(N,Kplus)\n",
    " \n",
    "    return(final_Z, final_K, final_sigma_A, final_sigma_X, final_alpha, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve Likelihood\n",
    "### Cython\n",
    "### Jit\n",
    "### Parallelization\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need revision\n",
    "**Part III: Defining original likelihood and likelihood with new inverse calculation method**\n",
    "**(\"log_p\" and \"log_p_new\")**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the finite model, the D-dimensional vector of properties of an object i, $x_i$ is generated from a Gaussian distribution with mean $z_i$A and covariance matrix $\\sum$X = $\\sigma$^2_X I, where $z_i$ is a K-dimensional binary vector, and A is a K $\\times$ D matrix of weights. In matrix notation, E[X] = ZA. If Z is a feature matrix, this is a form of binary factor analysis. The distribution of X given Z, A, and σ X is matrix Gaussian with mean ZA and covariance matrix $\\sigma$^2_X I, where I is the identity matrix. The prior on A is also matrix Gaussian, with mean 0 and covariance matrix $\\sigma$^2_X I. Integrating out A, we have:\n",
    "\n",
    "\\begin{multline}\n",
    "P(X|Z,\\sigma_X, \\sigma_A) = \\frac{1}{(2 \\pi)^{ND/2} (\\sigma_X)^{(N-K)D}(\\sigma_A)^{KD}(|Z^TZ+\\frac{\\sigma_X^2}{\\sigma_A^2}I|)^{D/2}}\\\\exp\\{-\\frac{1}{2\\sigma_X^2}tr(X^T(I-Z(Z^TZ+\\frac{\\sigma_X^2}{\\sigma_A^2}I)^{-1}Z^T)X)\\}\n",
    "\\end{multline}\n",
    "\n",
    "Based on these information from the paper, we simply implemented the likelihood function as below.\n",
    "\n",
    "Inspired by the formulas (23) and (24) in Griffiths and Ghahramani's[1] paper, we also tried to use the method to calculate inverse as below:\n",
    "\n",
    "(latex needed for the two formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting compare_matrix_inverse.py\n"
     ]
    }
   ],
   "source": [
    "%%file compare_matrix_inverse.py\n",
    "from original_functions import IBP_prior, calcInverse\n",
    "import numpy as np\n",
    "import time\n",
    "#check whether the inversion method described by Griffiths and Ghahramani(2005) works\n",
    "X=np.load('data/X_initialized.npy')\n",
    "N=X.shape[0]\n",
    "D=X.shape[1]\n",
    "sigmaX=1.\n",
    "sigmaA=1.\n",
    "alpha=1.\n",
    "i=2\n",
    "k=1\n",
    "Z,K = IBP_prior(alpha,N)\n",
    "M = np.linalg.inv(Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K))\n",
    "Z[i,k] = 1 - Z[i,k]\n",
    "loops = 1000\n",
    "t_calculate_inverse = np.zeros(loops)\n",
    "for l in range(loops):\n",
    "    t0=time.time()\n",
    "    calcInverse(Z,M,i,k)\n",
    "    t1=time.time()\n",
    "    t_calculate_inverse[l]=t1-t0\n",
    "mean_t_calculate_inverse = round(np.mean(t_calculate_inverse),7)\n",
    "\n",
    "\n",
    "t_linalg_inverse = np.zeros(loops)\n",
    "for l in range(loops):\n",
    "    t0=time.time()\n",
    "    np.linalg.inv(Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K))\n",
    "    t1=time.time()\n",
    "    t_linalg_inverse[l]=t1-t0\n",
    "mean_t_linalg_inverse= round(np.mean(t_linalg_inverse),7)\n",
    "\n",
    "\n",
    "aaaa = calcInverse(Z,M,i,k)\n",
    "bbbb = np.linalg.inv(Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K))\n",
    "\n",
    "results = np.array([aaaa,bbbb,mean_t_calculate_inverse,t_linalg_inverse])\n",
    "np.save(\"data/inverse_compare_results\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.testing as npt\n",
    "results = np.load(\"data/inverse_compare_results.npy\")\n",
    "# There are small portion of times that they don't almost equal\n",
    "npt.assert_almost_equal(results[0],results[1], decimal =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>calcInverse</th>\n",
       "      <td>1.7e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear algebra inverse</th>\n",
       "      <td>3e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Time\n",
       "calcInverse             1.7e-05\n",
       "linear algebra inverse    3e-05"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = ['Time']\n",
    "index = ['calcInverse','linear algebra inverse']\n",
    "times = results[2:4]\n",
    "df = pd.DataFrame(times,columns=columns,index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cythonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Cython/Cython_functions.pyx\n"
     ]
    }
   ],
   "source": [
    "%%file Cython/Cython_functions.pyx\n",
    "import numpy as np\n",
    "\n",
    "cimport numpy as np\n",
    "\n",
    "def IBP_prior(double alpha, int N):\n",
    "    cdef double p\n",
    "    cdef int i,j,K_plus,temp\n",
    "    cdef np.ndarray res\n",
    "    \n",
    "    res = np.zeros((N, 1000))\n",
    "    \n",
    "    temp = np.random.poisson(alpha)\n",
    "    if temp>0:\n",
    "        res[0,0:temp] = np.ones(temp)\n",
    "\n",
    "    K_plus = temp\n",
    "    for i in range(1,N):\n",
    "        for j in range(K_plus):\n",
    "            p = np.sum(res[0:i,j])/(i+1)\n",
    "            if np.random.uniform(0,1) < p:\n",
    "                res[i,j] = 1\n",
    "        temp = np.random.poisson(alpha/(i+1))\n",
    "        if temp > 0:\n",
    "            res[i, K_plus : K_plus + temp] = np.ones(temp)\n",
    "            K_plus = K_plus + temp\n",
    "    \n",
    "    res = res[:,0:K_plus]\n",
    "    return np.array((res, K_plus))\n",
    "\n",
    "#log p(X|Z,σ_x ,σ_A )\n",
    "def log_p(X, Z, double sigmaX, double sigmaA, int K, int D, int N):\n",
    "    M = Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K)\n",
    "    return (-0.5)*N*D*np.log(2*np.pi) - (N-K)*D*np.log(sigmaX) - K*D*np.log(sigmaA) -0.5*D*np.log(np.linalg.det(M)) -0.5/(sigmaX**2)*np.trace((X.T.dot(np.identity(N)-Z.dot(np.linalg.inv(M).dot(Z.T)))).dot(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Cython/Cython_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%file Cython/Cython_setup.py\n",
    "\n",
    "from distutils.core import setup, Extension\n",
    "from Cython.Build import cythonize\n",
    "import numpy as np\n",
    "\n",
    "ext = Extension(\"Cython_functions\",\n",
    "                sources=[\"Cython/Cython_functions.pyx\"],\n",
    "                include_dirs=[np.get_include()],\n",
    "                libraries=[\"m\"],\n",
    "                extra_compile_args=[\"-w\",  \"-std=c99\"])\n",
    "\n",
    "setup(name = \"Cy_Funcs\",\n",
    "      ext_modules = cythonize(ext),\n",
    "     include_dirs=[np.get_include()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Cython/Cython_functions.pyx because it changed.\n",
      "[1/1] Cythonizing Cython/Cython_functions.pyx\n",
      "running clean\n",
      "removing 'build/temp.macosx-10.5-x86_64-3.5' (and everything under it)\n",
      "removing 'build'\n"
     ]
    }
   ],
   "source": [
    "! python Cython/Cython_setup.py clean\n",
    "! python Cython/Cython_setup.py -q build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Cython/Cython_sampler.pyx\n"
     ]
    }
   ],
   "source": [
    "%%file Cython/Cython_sampler.pyx\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import math\n",
    "import Cython_functions as func\n",
    "def cy_sampler(double[:,:] X, int niter, double sigmaX, double sigmaA, double alpha, int N, int D, int maxNew):\n",
    "\n",
    "    \n",
    "    #initialization\n",
    "    cdef int count=0\n",
    "    cdef int j,i,kNew,kk,new,k\n",
    "    cdef double[:,:] Z\n",
    "    cdef double Log_L1,temp_unif\n",
    "    cdef double Harmonic_N,alphaN, lik, pois, p\n",
    "    cdef double temp_unif1, Log_L_New, sigmaX_a, U, sigmaA_new,sigmaX_new\n",
    "\n",
    "\n",
    "    final_Z=np.zeros((niter,N,20))\n",
    "    final_K=np.zeros((niter,1))\n",
    "    final_sigma_X=np.zeros((niter,1))\n",
    "    final_sigma_A=np.zeros((niter,1))\n",
    "    final_alpha=np.zeros((niter,1))\n",
    "    Z, Kplus = func.IBP_prior(alpha, N)\n",
    "    \n",
    "    #repeat \"niter\" number of times\n",
    "    for j in range(niter):\n",
    "        final_Z[count,:,0:Kplus] = Z\n",
    "        final_K[count] = Kplus\n",
    "        final_sigma_X[count] = sigmaX\n",
    "        final_sigma_A[count] = sigmaA\n",
    "        final_alpha[count] = alpha\n",
    "        count = count + 1\n",
    "\n",
    "        for i in range(N):\n",
    "            for k in range(Kplus):\n",
    "                if k >= Kplus:\n",
    "                    break     \n",
    "                if Z[i,k] > 0:\n",
    "                    if (np.sum(Z[:,k])- 1) <= 0:\n",
    "                        Z[:,k:(Kplus-1)] = Z[:,(k+1):Kplus]\n",
    "                        Kplus = Kplus-1\n",
    "                        Z = Z[:,0:Kplus]\n",
    "                        continue\n",
    "           \n",
    "\n",
    "           #M-H algorithm for Z\n",
    "                P = np.zeros(2)\n",
    "                #set Z[i,k] = 0 and calculate posterior probability\n",
    "                Z[i,k] = 0\n",
    "                P[0] = func.log_p(X, Z, sigmaX, sigmaA, Kplus, D, N) + np.log(N-np.sum(Z[:,k])) - np.log(N)\n",
    "                #set Z[i,k] = 1 and calculate posterior probability\n",
    "                Z[i,k] = 1\n",
    "                P[1] = func.log_p(X, Z,sigmaX, sigmaA, Kplus, D, N)  + np.log(np.sum(Z[:,k])- 1) - np.log(N)\n",
    "\n",
    "                P = np.exp(P - max(P))\n",
    "                U = np.random.uniform(0,1)\n",
    "                if U<(P[1]/(np.sum(P))):\n",
    "                    Z[i,k] = 1\n",
    "                else:\n",
    "                    Z[i,k] = 0   \n",
    "  \n",
    "\n",
    "            #M-H algorithm for k\n",
    "            # Set the number of upper bound as 3\n",
    "            maxNew = 3\n",
    "            #Sample number of new features\n",
    "            prob = np.zeros(maxNew)\n",
    "            alphaN = alpha/N     \n",
    "            for kNew in range(maxNew):\n",
    "                Z_temp = Z\n",
    "                if kNew > 0:\n",
    "                    addCols = np.zeros((N,kNew))\n",
    "                    addCols[i,:] = 1\n",
    "                    Z_temp = np.hstack((Z_temp, addCols))\n",
    "\n",
    "                pois = kNew*np.log(alphaN) - alphaN - np.log(math.factorial(kNew))\n",
    "                kk = Kplus+kNew\n",
    "                lik = func.log_p(X, Z_temp, sigmaX, sigmaA, kk, D, N)\n",
    "                prob[kNew] = pois + lik\n",
    "            prob = np.exp(prob - max(prob))\n",
    "            prob = prob/sum(prob)\n",
    "\n",
    "            U = np.random.uniform(0,1)\n",
    "            p = 0\n",
    "            kNew=0\n",
    "            for new in range(maxNew):\n",
    "                p = p + prob[new]\n",
    "                if U < p:\n",
    "                    kNew = new\n",
    "                    break\n",
    "            if kNew > 0:\n",
    "                addCols = np.zeros((N,kNew))\n",
    "                addCols[i,:] = 1\n",
    "                Z = np.hstack((Z, addCols))\n",
    "            Kplus = Kplus + kNew \n",
    "        Log_L1 = func.log_p(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "\n",
    "\n",
    "        #update sigmaX  \n",
    "        temp_unif = np.random.uniform(0,1)/30\n",
    "        if np.random.uniform(0,1) < .5:\n",
    "            sigmaX_new = sigmaX - temp_unif\n",
    "        else:\n",
    "            sigmaX_new = sigmaX + temp_unif\n",
    "    \n",
    "        Log_L_New = func.log_p(X, Z, sigmaX_new, sigmaA, Kplus, D, N)\n",
    "        sigmaX_a = np.exp(min(0,Log_L_New-Log_L1))       \n",
    "        U = np.random.uniform(0,1)\n",
    "        if U < sigmaX_a:\n",
    "            sigmaX = sigmaX_new\n",
    "\n",
    "\n",
    "        #update sigmaA\n",
    "        temp_unif1 = np.random.uniform(0,1)/30\n",
    "        if np.random.uniform(0,1) < .5:\n",
    "            sigmaA_new = sigmaA - temp_unif1\n",
    "        else:\n",
    "            sigmaA_new = sigmaA + temp_unif1\n",
    "    \n",
    "        Log_L_New = func.log_p(X, Z, sigmaX, sigmaA_new, Kplus, D, N)\n",
    "        sigmaX_a = np.exp(min(0,Log_L_New-Log_L1))\n",
    "        U = np.random.uniform(0,1)\n",
    "        if U < sigmaX_a:\n",
    "            sigmaA = sigmaA_new\n",
    "        \n",
    "\n",
    "        #update alpha\n",
    "        Harmonic_N = 0.\n",
    "        for i in range(1, N+1):\n",
    "            Harmonic_N += 1.0/i\n",
    "        alpha = np.random.gamma(1+Kplus, 1/(1+Harmonic_N))  \n",
    " \n",
    "    return(final_Z, final_K, final_sigma_A, final_sigma_X, final_alpha, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Cython/Cython_setup_sampler.py\n"
     ]
    }
   ],
   "source": [
    "%%file Cython/Cython_setup_sampler.py\n",
    "\n",
    "from distutils.core import setup, Extension\n",
    "from Cython.Build import cythonize\n",
    "import numpy as np\n",
    "\n",
    "ext = Extension(\"Cython_sampler\",\n",
    "                sources=[\"Cython/Cython_sampler.pyx\"],\n",
    "                include_dirs=[np.get_include()],\n",
    "                libraries=[\"m\"],\n",
    "                extra_compile_args=[\"-w\",  \"-std=c99\"])\n",
    "\n",
    "setup(name = \"Cy_sampler\",\n",
    "      ext_modules = cythonize(ext),\n",
    "     include_dirs=[np.get_include()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Cython/Cython_sampler.pyx because it changed.\n",
      "[1/1] Cythonizing Cython/Cython_sampler.pyx\n",
      "running clean\n",
      "removing 'build/temp.macosx-10.5-x86_64-3.5' (and everything under it)\n",
      "removing 'build'\n"
     ]
    }
   ],
   "source": [
    "! python Cython/Cython_setup_sampler.py clean\n",
    "! python Cython/Cython_setup_sampler.py -q build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: Algorithm implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before conducting optimization, we first test whether the code above works and give up a desired result similar to that in the paper. This is tested by checking the traceplot of certain variable and drawing the picture based from \"A\", which is the same as that in the paper. \n",
    "\n",
    "As is set in the paper: \"The Gibbs sampler was initialized with K+ = 1, choosing the feature assignments for the first column by setting $z_i1$ = 1 with probability 0.5. $\\sigma_A$, $\\sigma_X$ , and $\\alpha$ were initially set to 0.5, 1.7, and 1 respectively\". To get a trace plot, parameters $\\alpha$, $\\sigma_A$ and $\\sigma_X$ are sampled over 1000 iterations with 200 burn-in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scripts/compare_sampler.py\n"
     ]
    }
   ],
   "source": [
    "%%file scripts/compare_sampler.py\n",
    "import time\n",
    "import numpy as np\n",
    "from Cython_sampler import cy_sampler\n",
    "import math\n",
    "import Cython_functions as func\n",
    "from Original_sampler import sampler\n",
    "from gibbs_sampler import Update_Z,Update_Kplus,Update_sigmaX,Update_sigmaA,Update_alpha\n",
    "from original_functions import log_p, log_p_origin, IBP_prior\n",
    "X=np.load('data/X_initialized.npy')\n",
    "niter = 1500\n",
    "N = 100 \n",
    "D = 36 \n",
    "sigmaX = 1.7\n",
    "sigmaA = 0.5\n",
    "alpha = 1.0\n",
    "maxNew = 4\n",
    "BURN_IN=200\n",
    "SAMPLE_SIZE= niter-BURN_IN\n",
    "np.random.seed(124)\n",
    "t0=time.time()\n",
    "chain1_Z, chain1_K, chain1_sigma_A, chain1_sigma_X, chain1_alpha, Z1= sampler(X, niter, sigmaX, sigmaA, alpha, N, D, maxNew, log_p_origin)  \n",
    "t1=time.time()-t0\n",
    "\n",
    "np.save(\"data/chain1/chain1Z\", chain1_Z)\n",
    "np.save(\"data/chain1/chain1K\",chain1_K)\n",
    "np.save(\"data/chain1/chain1SigmaX\", chain1_sigma_X)\n",
    "np.save(\"data/chain1/chain1SigmaA\",chain1_sigma_A)\n",
    "np.save(\"data/chain1/chain1Alpha\", chain1_alpha) \n",
    "np.random.seed(124)\n",
    "t0=time.time()\n",
    "chain2_Z, chain2_K, chain2_sigma_A, chain2_sigma_X, chain2_alpha, Z2= sampler(X, niter, sigmaX, sigmaA, alpha, N, D, maxNew, log_p)  \n",
    "t2=time.time()-t0\n",
    "\n",
    "np.save(\"data/chain2/chain2Z\", chain2_Z)\n",
    "np.save(\"data/chain2/chain2K\",chain2_K)\n",
    "np.save(\"data/chain2/chain2SigmaX\", chain2_sigma_X)\n",
    "np.save(\"data/chain2/chain2SigmaA\",chain2_sigma_A)\n",
    "np.save(\"data/chain2/chain2Alpha\", chain2_alpha) \n",
    "np.random.seed(124)\n",
    "t0=time.time()\n",
    "chain3_Z, chain3_K, chain3_sigma_A, chain3_sigma_X, chain3_alpha, Z3= cy_sampler(X, niter, sigmaX, sigmaA, alpha, N, D, maxNew)  \n",
    "t3=time.time()-t0\n",
    "\n",
    "np.save(\"data/chain3/chain3Z\", chain3_Z)\n",
    "np.save(\"data/chain3/chain3K\",chain3_K)\n",
    "np.save(\"data/chain3/chain3SigmaX\", chain3_sigma_X)\n",
    "np.save(\"data/chain3/chain3SigmaA\",chain3_sigma_A)\n",
    "np.save(\"data/chain3/chain3Alpha\", chain3_alpha) \n",
    "\n",
    "np.save(\"data/sampler_time\", np.array([t1,t2,t3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sampler_original_likelihood</th>\n",
       "      <td>343.168945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampler_improved_likelihood</th>\n",
       "      <td>316.431679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cythonized_sampler</th>\n",
       "      <td>302.441189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Time(s)\n",
       "sampler_original_likelihood  343.168945\n",
       "sampler_improved_likelihood  316.431679\n",
       "Cythonized_sampler           302.441189"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "times = np.load(\"data/sampler_time.npy\")\n",
    "columns = ['Time(s)']\n",
    "index = ['sampler_original_likelihood','sampler_improved_likelihood','Cythonized_sampler']\n",
    "df = pd.DataFrame(times,columns=columns,index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cythonized functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XRecreated=np.zeros((N,D))\n",
    "Z=Z[:,0:4]\n",
    "sigma_X=np.mean(chain_sigma_X[BURN_IN:niter])\n",
    "sigma_A=np.mean(chain_sigma_A[BURN_IN:niter])\n",
    "A_inf=np.dot(np.dot(np.linalg.inv((np.dot(Z.T,Z)+(sigmaX/sigmaA)*np.eye(4))),Z.T),X)\n",
    "\n",
    "for i in range(N):\n",
    "    XRecreated[i,:]=np.dot(Z[i,:],A_inf[0:4,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior estimation of A is given by:\n",
    "E[A|X,Z]=(ZZ+σA2I) ZX\n",
    "as given in Griffiths and Ghahramani(2005) [2] eq.59. For this calculation, we used the final Z obtained from the MC with only the first four columns corresponding to the four detected features. Likewise, posterior means of σX and σA were used in the calculation of posterior estimation of weight matrix A.\n",
    "\n",
    "With this information and the posterior Z, we were able to recreate the objects X as: xi ∼Normal(ziA,0)\n",
    "We used zero variance to ignore the white noise in the recreated images. The results are shown in Fig. 4. By comparing with the original features and simulated objects as given in Fig. 3 with the detected features and recreated objects as given in Fig. 4, we can conclude that the algorithm was successfull in identifying all the latent features and successfully detecting the presense or absence of those features in the simulated objects which had white noise making detection difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 images were generated as binary linear combinations of four sets of\n",
    "class weights, shown in the images on the top. The images on the bottom are the posterior\n",
    "mean weights A for a single sample of Z after 200 iterations, ordered to match the true\n",
    "classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x118b3aa20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2YAAADtCAYAAADUSmZ4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuj4DFWqBlEkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115819d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initial plots\n",
    "plt.figure(num=None, figsize=(15,3.5), dpi=100, facecolor='w', edgecolor='k')\n",
    "plt.subplot(141)\n",
    "plt.pcolormesh(A[0,:].reshape(6,6),cmap=plt.cm.gray)     \n",
    "plt.subplot(142)\n",
    "plt.pcolormesh(A[1,:].reshape(6,6),cmap=plt.cm.gray)  \n",
    "plt.subplot(143)\n",
    "plt.pcolormesh(A[2,:].reshape(6,6),cmap=plt.cm.gray)  \n",
    "plt.subplot(144)\n",
    "plt.pcolormesh(A[3,:].reshape(6,6),cmap=plt.cm.gray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x118e8c898>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2YAAADtCAYAAADUSmZ4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118ac03c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(num=None, figsize=(15,3.5), dpi=100, facecolor='w', edgecolor='k')\n",
    "plt.subplot(141)\n",
    "plt.pcolormesh(XRecreated[1,:].reshape(6,6),cmap=plt.cm.gray)\n",
    "plt.subplot(142)\n",
    "plt.pcolormesh(XRecreated[2,:].reshape(6,6),cmap=plt.cm.gray)\n",
    "plt.subplot(143)\n",
    "plt.pcolormesh(XRecreated[3,:].reshape(6,6),cmap=plt.cm.gray)\n",
    "plt.subplot(144)\n",
    "plt.pcolormesh(XRecreated[98,:].reshape(6,6),cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From left to right: 0010, 0101, 1100, 1011\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, the latent feature model is able to ”reverse” the noisy images to the linear combination of latent features. Figure 7 is an example of the first four images in the simulated dataset: The top row contains the ”reversed” images, and the latent features in each one can be clearly seen. The bottom row represents the original images, in which the latent features are obscured by the random noise. The binary strings on top of all images indicate which bases are present in which image; for example, the string ”1100” represents an image as a linear combination of the first and second bases, without the third and fourth ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detected Features, First four recreated objects and the features present in each of the objects. First row shows the 4 latent features used detected by MCMC. Second row shows the first four recreated objects. Light signifies presence and dark signifies the absence of the feature for any given object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part VI: Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Option1: Concurrent Parallization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here using parallization is worth trying and can be validated. When the computation is done in parallel on the K processors, we can see that computation on processors where the condition is not met is ’thrown away’. So on every processor, we count the rejections out and then take the total amount and keep moving. That is to say, we can break the whole process into several pieces and the result can be combined back for the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: The trace plot are the same, by comparing the time, we can see that the ue parallel computing will dramatically improve efficiency.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using sampler_new which contains log_p_new with a new way of calculating inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option2: JIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "\n",
    "def numba_sampler(X, niter, sigmaX, sigmaA, alpha, N, D, maxNew, log_p):\n",
    "\n",
    "    \n",
    "    #initialization\n",
    "    count=0\n",
    "    final_Z=np.zeros((niter,N,20))\n",
    "    final_K=np.zeros((niter,1))\n",
    "    final_sigma_X=np.zeros((niter,1))\n",
    "    final_sigma_A=np.zeros((niter,1))\n",
    "    final_alpha=np.zeros((niter,1))\n",
    "    Z, Kplus = IBP_prior(alpha, N)\n",
    "    \n",
    "    #repeat \"niter\" number of times\n",
    "    for j in range(niter):\n",
    "        final_Z[count,:,0:Kplus] = Z\n",
    "        final_K[count] = Kplus\n",
    "        final_sigma_X[count] = sigmaX\n",
    "        final_sigma_A[count] = sigmaA\n",
    "        final_alpha[count] = alpha\n",
    "        count = count + 1\n",
    "\n",
    "        for i in range(N):\n",
    "            for k in range(Kplus):\n",
    "                if k >= Kplus:\n",
    "                    break     \n",
    "                if Z[i,k] > 0:\n",
    "                    if (np.sum(Z[:,k])- 1) <= 0:\n",
    "                        Z[:,k:(Kplus-1)] = Z[:,(k+1):Kplus]\n",
    "                        Kplus = Kplus-1\n",
    "                        Z = Z[:,0:Kplus]\n",
    "                        continue\n",
    "           \n",
    "\n",
    "           #M-H algorithm for Z\n",
    "                P = np.zeros(2)\n",
    "                #set Z[i,k] = 0 and calculate posterior probability\n",
    "                Z[i,k] = 0\n",
    "                P[0] = log_p(X, Z, sigmaX, sigmaA, Kplus, D, N) + np.log(N-np.sum(Z[:,k])) - np.log(N)\n",
    "                #set Z[i,k] = 1 and calculate posterior probability\n",
    "                Z[i,k] = 1\n",
    "                P[1] = log_p(X, Z,sigmaX, sigmaA, Kplus, D, N)  + np.log(np.sum(Z[:,k])- 1) - np.log(N)\n",
    "\n",
    "                P = np.exp(P - max(P))\n",
    "                U = np.random.uniform(0,1)\n",
    "                if U<(P[1]/(np.sum(P))):\n",
    "                    Z[i,k] = 1\n",
    "                else:\n",
    "                    Z[i,k] = 0   \n",
    "  \n",
    "\n",
    "            #M-H algorithm for k\n",
    "            # Set the number of upper bound as 3\n",
    "            maxNew = 3\n",
    "            #Sample number of new features\n",
    "            prob = np.zeros(maxNew)\n",
    "            alphaN = alpha/N     \n",
    "            for kNew in range(maxNew):\n",
    "                Z_temp = Z\n",
    "                if kNew > 0:\n",
    "                    addCols = np.zeros((N,kNew))\n",
    "                    addCols[i,:] = 1\n",
    "                    Z_temp = np.hstack((Z_temp, addCols))\n",
    "\n",
    "                pois = kNew*np.log(alphaN) - alphaN - np.log(math.factorial(kNew))\n",
    "                kk = Kplus+kNew\n",
    "                lik = log_p(X, Z_temp, sigmaX, sigmaA, kk, D, N)\n",
    "                prob[kNew] = pois + lik\n",
    "            prob = np.exp(prob - max(prob))\n",
    "            prob = prob/sum(prob)\n",
    "\n",
    "            U = np.random.uniform(0,1)\n",
    "            p = 0\n",
    "            kNew=0\n",
    "            for new in range(maxNew):\n",
    "                p = p + prob[new]\n",
    "                if U < p:\n",
    "                    kNew = new\n",
    "                    break\n",
    "            if kNew > 0:\n",
    "                addCols = np.zeros((N,kNew))\n",
    "                addCols[i,:] = 1\n",
    "                Z = np.hstack((Z, addCols))\n",
    "            Kplus = Kplus + kNew \n",
    "        Log_L1 = log_p(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "\n",
    "\n",
    "        #update sigmaX  \n",
    "        temp_unif = np.random.uniform(0,1)/30\n",
    "        if np.random.uniform(0,1) < .5:\n",
    "            sigmaX_new = sigmaX - temp_unif\n",
    "        else:\n",
    "            sigmaX_new = sigmaX + temp_unif\n",
    "    \n",
    "        Log_L_New = log_p(X, Z, sigmaX_new, sigmaA, Kplus, D, N)\n",
    "        sigmaX_a = np.exp(min(0,Log_L_New-Log_L1))       \n",
    "        U = np.random.uniform(0,1)\n",
    "        if U < sigmaX_a:\n",
    "            sigmaX = sigmaX_new\n",
    "\n",
    "\n",
    "        #update sigmaA\n",
    "        temp_unif1 = np.random.uniform(0,1)/30\n",
    "        if np.random.uniform(0,1) < .5:\n",
    "            sigmaA_new = sigmaA - temp_unif1\n",
    "        else:\n",
    "            sigmaA_new = sigmaA + temp_unif1\n",
    "    \n",
    "        Log_L_New = log_p(X, Z, sigmaX, sigmaA_new, Kplus, D, N)\n",
    "        sigmaX_a = np.exp(min(0,Log_L_New-Log_L1))\n",
    "        U = np.random.uniform(0,1)\n",
    "        if U < sigmaX_a:\n",
    "            sigmaA = sigmaA_new\n",
    "        \n",
    "\n",
    "        #update alpha\n",
    "        Harmonic_N = 0.\n",
    "        for i in range(1, N+1):\n",
    "            Harmonic_N += 1.0/i\n",
    "        alpha = np.random.gamma(1+Kplus, 1/(1+Harmonic_N))  \n",
    " \n",
    "    return(final_Z, final_K, final_sigma_A, final_sigma_X, final_alpha, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file scripts/compare_jit_with_original\n",
    "import time\n",
    "X=np.load('data/X_initialized.npy')\n",
    "niter = 1500\n",
    "N = 100 \n",
    "D = 36 \n",
    "sigmaX = 1.7\n",
    "sigmaA = 0.5\n",
    "alpha = 1.0\n",
    "maxNew = 4\n",
    "BURN_IN=200\n",
    "SAMPLE_SIZE= niter-BURN_IN\n",
    "np.random.seed(124)\n",
    "t0 = time.time()\n",
    "chain4_Z, chain4_K, chain4_sigma_A, chain4_sigma_X, chain4_alpha, Z4 = numba_sampler(X, niter, sigmaX, sigmaA, alpha, N, D, maxNew, log_p_origin)\n",
    "t4 = time.time()-t0\n",
    "np.save(\"data/jit_time\",t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'hstack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b9e502e6f548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Time(s)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sampler_original_likelihood'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sampler_improved_likelihood'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Cythonized_sampler'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'jit_original-likelihood'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'hstack'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "times = np.load(\"data/sampler_time.npy\")\n",
    "jit_time = np.load(\"jit_time.npy\")\n",
    "columns = ['Time(s)']\n",
    "index = ['sampler_original_likelihood','sampler_improved_likelihood','Cythonized_sampler','jit_original-likelihood']\n",
    "df = pd.DataFrame(times.hstack(jit_time),columns=columns,index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343.16894507408142, array(354.6639549732208))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times[0],jit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414.01697516441345"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1181dd860>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEJCAYAAABhbdtlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11616c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(chain4_sigma_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing difference between JIT and the original takes extremely long time, but the results do not show much difference. Thus in this case, using JIT is not appropriate. Since we are measuring a quite long running program, it may take some time for the JIT to warm up and this may cause the difference. While the effect of JIT is not that impressive, we can try to count on CPython which is generally more optimized.The JIT is generally good at speeding up straight-forward Python code that spends a lot of time in the bytecode dispatch loop, i.e., running actual Python code – as opposed to running things that only are invoked by Python code. When the JIT cannot help, we could use CPython."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Conclusion: There seems to be little difference between JIT version and the original version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part VII: Conclusions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Griffiths, Thomas L., and Zoubin Ghahramani. \"The indian buffet process: An introduction and review.\" The Journal of Machine Learning Research 12 (2011): 1185-1224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
